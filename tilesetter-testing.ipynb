{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76465a86",
   "metadata": {},
   "source": [
    "# tileSetter Testing & Process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff52d59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating stuck name prefixes ...\n",
      "A markers tagged: 7\n",
      "B markers tagged: 6\n",
      "C markers tagged: 7\n",
      "D markers tagged: 3\n",
      "F markers tagged: 4\n",
      "G markers tagged: 2\n",
      "J markers tagged: 1\n",
      "K markers tagged: 5\n",
      "L markers tagged: 7\n",
      "M markers tagged: 7\n",
      "N markers tagged: 2\n",
      "P markers tagged: 6\n",
      "R markers tagged: 4\n",
      "S markers tagged: 14\n",
      "T markers tagged: 6\n",
      "Active prefixes updated!\n",
      "\n",
      "Names Updated!\n",
      "Generator\n",
      "------------------\n",
      "  pieces Lmin Lmax              regex\n",
      "0   bit*    3    5  [a-z][a-z][a-z]..\n",
      "1   bit*    2    3        [a-z][a-z].\n",
      "------------------\n",
      "\n",
      "Name Stats\n",
      "Stuck? True\n",
      "--------------\n",
      "           NUM\n",
      "5 Letters   75\n",
      "6 Letters   76\n",
      "7 Letters   76\n",
      "8 Letters   75\n",
      "           ---\n",
      "All Names  302\n",
      "--------------\n",
      "Last Update @ 09:50:54 PM\n",
      "\n",
      "Loaded name generator 'bb'.Open /HTML/tileSetter.html in your favorite browser to see the tiles!\n",
      "To generate more names, type 'refresh(bb)')\n",
      "or create new name generator using nb.nameGen().\n"
     ]
    }
   ],
   "source": [
    "from pyleSetter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81db0278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A markers tagged: 7\n",
      "B markers tagged: 6\n",
      "C markers tagged: 7\n",
      "D markers tagged: 3\n",
      "F markers tagged: 4\n",
      "G markers tagged: 2\n",
      "J markers tagged: 1\n",
      "K markers tagged: 5\n",
      "L markers tagged: 7\n",
      "M markers tagged: 7\n",
      "N markers tagged: 2\n",
      "P markers tagged: 6\n",
      "R markers tagged: 4\n",
      "S markers tagged: 14\n",
      "T markers tagged: 6\n",
      "Active prefixes updated!\n"
     ]
    }
   ],
   "source": [
    "#newbie = nb.w_s.loc[:,nb.w_s.columns!='cvc']\n",
    "#newbie.to_csv('./data/word-segments.csv',in)\n",
    "#'dragon'[0:3]\n",
    "w_s2 = update_pres(nb.w_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57e4a181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bit</th>\n",
       "      <th>L</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84331</th>\n",
       "      <td>beo</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bit    L prefix\n",
       "84331  beo  3.0   True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = w_s2[w_s2.prefix==True]\n",
    "test[test.L==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3d313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23101cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tagger:\n",
    "    def __init__(self, tag, single=False,**attrs):\n",
    "        self.tag = tag\n",
    "        self.ats = self.check_for_class(attrs)\n",
    "        self.single = single\n",
    "\n",
    "        if single==True:\n",
    "            self.openr = ' />'\n",
    "            self.tagclosed = ''\n",
    "        else:\n",
    "            self.openr = '>'\n",
    "            self.tagclosed = '</' + tag + '>'\n",
    "\n",
    "    def check_for_class(self,attributes):\n",
    "        if 'class_' in attributes.keys():\n",
    "            attributes['class'] = attributes.pop('class_')\n",
    "        return attributes\n",
    "\n",
    "    def wrap(self, to_wrap, wrap_by='lines', **attrs):\n",
    "        attrs = self.check_for_class(attrs)\n",
    "        #print(attrs)\n",
    "        tagclosed = self.tagclosed\n",
    "\n",
    "        if wrap_by == 'lines':\n",
    "            wrapper = pd.DataFrame()\n",
    "            tagopen = self.open_tag(attrs.copy())\n",
    "            #print(tagopen)\n",
    "\n",
    "\n",
    "            if type(tagopen) == pd.Series:\n",
    "                wrapper['open'] = tagopen\n",
    "            elif type(tagopen) == str:\n",
    "                open = pd.Series(tagopen,index = range(0,len(to_wrap)))\n",
    "                wrapper['open'] = open\n",
    "\n",
    "            wrapper['content'] = '\\t' + to_wrap\n",
    "            wrapper['closed'] = tagclosed\n",
    "            #print(wrapper.stack().explode().swaplevel(0,1))\n",
    "            wrapper['tag'] = wrapper.open.astype(str) + \\\n",
    "                             wrapper.content.astype(str) + \\\n",
    "                             wrapper.closed.astype(str)\n",
    "            wrapped = wrapper['tag']#wrapper['tag']\n",
    "\n",
    "\n",
    "        elif wrap_by == 'block':\n",
    "\n",
    "            content = to_wrap\n",
    "            if type(to_wrap) == list:\n",
    "                content = pd.Series(to_wrap)\n",
    "            if type(content) == pd.Series:\n",
    "                content = '\\t'+content\n",
    "                content = content.values.tolist()\n",
    "            elif type(content) == str:\n",
    "                content = [ '\\t'+content ]\n",
    "            else:\n",
    "                print('Unable to block wrap.')\n",
    "                return\n",
    "\n",
    "            wrapper = [ self.open_tag(attrs.copy()) ] + content + [ tagclosed ]\n",
    "            wrapped = pd.Series(wrapper)\n",
    "\n",
    "        return wrapped\n",
    "\n",
    "    def open_tag(self,attrs):\n",
    "\n",
    "        ats = self.ats.copy()\n",
    "        ats.update(attrs.copy())\n",
    "        tag_open = '<' + self.tag\n",
    "        for attribute,value in ats.items():\n",
    "            if type(value) == str:\n",
    "                tag_open += ' {}=\"{}\"'.format(attribute,value)\n",
    "            elif type(value) == pd.Series:\n",
    "\n",
    "                tag_open += ' ' + attribute + '=\"' + value + '\"'\n",
    "        tag_open += self.openr\n",
    "\n",
    "        return tag_open\n",
    "\n",
    "    def add_attributes(self,**attrs):\n",
    "        check = self.check_for_class(attrs)\n",
    "        self.ats.update(check)\n",
    "\n",
    "    def copy(self):\n",
    "        new_boi = self\n",
    "        return new_boi\n",
    "\n",
    "\n",
    "a = Tagger('a', href='')\n",
    "img = Tagger('img', single=True, src='' )\n",
    "div = Tagger('div')\n",
    "p = Tagger('p')\n",
    "h2 = Tagger('h2')\n",
    "h1 = Tagger('h1')\n",
    "br = Tagger('br',single=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c74f3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_HTML(unpack_me):\n",
    "        # unpacks HTML from dictionary into pandas series\n",
    "        page = []\n",
    "        for keys,values in unpack_me.items():\n",
    "            page += values.tolist()\n",
    "            page += ['\\n']\n",
    "\n",
    "        page = pd.Series(page)\n",
    "        return page\n",
    "\n",
    "\n",
    "def get_pet_links(names,img_no='1'):\n",
    "\n",
    "    # image URL\n",
    "    names['img'] = 'http://pets.neopets.com/cpn/' +\\\n",
    "                    names.Neopet + '/1/'+img_no+'.png'\n",
    "    \n",
    "    # URLs to important places\n",
    "    names['petpage'] = 'http://neopets.com/~' + names.Neopet\n",
    "    names['pound'] = 'http://neopets.com/pound/adopt.phtml?search=' + names.Neopet\n",
    "    names['lookup'] = 'http://neopets.com/petlookup.phtml?pet=' + names.Neopet\n",
    "\n",
    "    return names\n",
    "\n",
    "\n",
    "def get_pet_tiles(names,link_to='petpage',tiyg=False):\n",
    "    \n",
    "    # Create tiles\n",
    "    ps = div.wrap(p.wrap(names.Neopet),class_=\"pet\",\n",
    "                    style = \"background: url('\"+ names.img + \"');\")\n",
    "\n",
    "    # Make tiles circles if updating Tiyg's petpage\n",
    "    a_style = ''\n",
    "    if tiyg == True:\n",
    "        a_style = \"border-radius:80px;\"\n",
    "\n",
    "    # Add pet tile HTML column to 'names'\n",
    "    names['pet_div'] = a.wrap(  ps,href=names[link_to],\n",
    "                                style=a_style )\n",
    "    return names\n",
    "\n",
    "def make_L_divs(names):\n",
    "        divdict = {}\n",
    "        for i in names.L.unique():\n",
    "            nameslice = names[names.L == i]\n",
    "\n",
    "            i_name = str(i) + ' Letters'\n",
    "            iL_div =  [ h2.wrap(i_name,wrap_by='block') ]\n",
    "            iL_div += nameslice.pet_div.values.tolist()\n",
    "            iL_div = pd.Series(iL_div)\n",
    "            Ldiv = div.wrap(iL_div,wrap_by='block',class_='petgroup')\n",
    "\n",
    "            divdict[i_name] = Ldiv.explode()\n",
    "        return divdict\n",
    "\n",
    "def tileSet(names,linkto='petpage'):\n",
    "    css = '<link rel=\"stylesheet\" type=\"text/css\" href=\"style.css\">'\n",
    "    css = pd.Series(css)\n",
    "    sort_pets_by = {'by':['L','Neopet']}\n",
    "    \n",
    "    names0 = names.copy()\n",
    "    names0['Neopet'] = names0.Neopet.str.replace('~','_')\n",
    "    names1 = get_pet_links(names0, img_no='1') # get pet links\n",
    "    names2 = get_pet_tiles(names1, link_to=linkto) # get pet tile HTML\n",
    "    \n",
    "    page = {'css': css}\n",
    "    \n",
    "    divs = make_L_divs(names2) # sort pet tiles into divs based on name length\n",
    "    \n",
    "    page.update(divs)\n",
    "    \n",
    "    html = unpack_HTML(page)\n",
    "    \n",
    "    html.to_csv('./HTML/tileSet.html', sep=',', header=False,\n",
    "                index=False, quoting=csv.QUOTE_NONE,\n",
    "                escapechar='\\n')\n",
    "    \n",
    "    print('HTML Updated!')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe69e96",
   "metadata": {},
   "source": [
    "## Word Segment Loading &  Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8319e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--! Import New Segments ------------------------------------------ #\n",
    "def new_segments(filepath,old_df=''):\n",
    "    # Imports a csv file containing a list of word/name new_segments\n",
    "    # Integrates segments into existing segment data\n",
    "\n",
    "    segments = pd.read_csv(filepath)\n",
    "    print('New word segments loaded.')\n",
    "    clean_seg = segment_cleaner(segments)\n",
    "    print('New word segments cleaned + determined length + cvc format')\n",
    "    labeled = label_pres(clean_seg)\n",
    "    print('New prefixes labeled.')\n",
    "\n",
    "    input1 = input('Would you like to merge new segments with existing segments? y/n\\n')\n",
    "    if input1 == 'y':\n",
    "        output = merge_segments(labeled,old_df)\n",
    "        print('Merge accepted. Returning merged segment dataframe.')\n",
    "    elif input1 =='n':\n",
    "        print('Merge declined. Returning new segments only.')\n",
    "        output = labeled\n",
    "    else:\n",
    "        print('Invalid input. Defaulting to return new segments only.')\n",
    "    return output\n",
    "\n",
    "#--! Merge new segments into old segments -------------------------- #\n",
    "def merge_segments(new,old):\n",
    "    if old == '':\n",
    "        error('No existing word segment data found.')\n",
    "    else:\n",
    "        merged = pd.concat([new,old],ignore_index=True).sort_values(by='bit')\n",
    "        merged = merged.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        input = ('Word segment data merged. Would you like to save? y/n')\n",
    "        if input == 'y':\n",
    "            fname = 'WS_' + str(dt.date.today) + '.csv'\n",
    "            merged.to_csv('./data/word-segments/' + fname,index=False)\n",
    "            merged.to_csv('./data/word-segments.csv',index=False)\n",
    "\n",
    "    return merged\n",
    "\n",
    "#--! Word Segment Cleaner ------------------------------------------- #\n",
    "def segment_cleaner(df):\n",
    "    # Takes in a series of word/name segments\n",
    "    # Returns dataframe with segments + length + cvc format\n",
    "\n",
    "    df = df.drop_duplicates().sort_values() # Drop duplicates\n",
    "    df = df[~df.str.contains(r'[_0-9]')].reset_index(drop=True) # Remove non-letters\n",
    "\n",
    "    Ls = df.str.len() # get length\n",
    "\n",
    "    # Construct dataframe\n",
    "    final = pd.DataFrame({})\n",
    "    final.insert(loc=0,column='bit',value=df)\n",
    "    final.insert(loc=1,column='L',value=Ls)\n",
    "    return final\n",
    "\n",
    "# #--! Label Segments As Prefixes ------------------------------------- #\n",
    "def update_pres(bit_df, abcs=string.ascii_lowercase):\n",
    "\n",
    "    stucks = pd.read_csv('./data/stuck-strings.csv')\n",
    "    stucks = stucks.replace('\\_','~',regex=True)\n",
    "    stucks = stucks[~stucks.prefix.str.startswith('~')].reset_index(drop=True)\n",
    "    markers = stucks.marker.str.lower()\n",
    "    \n",
    "    bit_df['prefix'] = False\n",
    "    N_tagged = 1\n",
    "    for n,i in enumerate(markers):\n",
    "        if n>0 :\n",
    "            if markers[n][0] != markers[n-1][0]:\n",
    "                print(markers[n-1][0].upper()+' markers tagged: '+ str(N_tagged))\n",
    "                N_tagged = 1\n",
    "            elif n == len(markers)-1:\n",
    "                N_tagged += 1\n",
    "                print(markers[n-1][0].upper()+' markers tagged: '+ str(N_tagged))\n",
    "            else:\n",
    "                N_tagged += 1\n",
    "\n",
    "        sliced = bit_df[bit_df.bit.str.startswith(i[0:3])].copy()\n",
    "        # Get regex filter string\n",
    "        F = get_regex(i)\n",
    "        \n",
    "        # Tag prefixes that match regex as 'True'\n",
    "        sliced.loc[sliced.bit.str.match(F),'prefix'] = True\n",
    "        \n",
    "        bit_df.update(sliced)\n",
    "    print('Active prefixes updated!')\n",
    "    return bit_df\n",
    "\n",
    "# def update_pres(bit_df, abcs=string.ascii_lowercase):\n",
    "\n",
    "#     stucks = pd.read_csv('./data/stuck-strings.csv')\n",
    "#     stucks = stucks.replace('\\_','~',regex=True)\n",
    "#     stucks = stucks[~stucks.prefix.str.startswith('~')].reset_index(drop=True)\n",
    "#     markers = stucks.marker.str.lower()\n",
    "\n",
    "#     print('Updating stuck name prefixes ...')\n",
    "#     bit_df['prefix'] = False\n",
    "#     N_tagged = 1\n",
    "#     for n,i in enumerate(markers):\n",
    "#         if n>0 :\n",
    "#             if markers[n][0] != markers[n-1][0]:\n",
    "#                 print(markers[n-1][0].upper()+' markers tagged: '+ str(N_tagged))\n",
    "#                 N_tagged = 1\n",
    "#             elif n == len(markers)-1:\n",
    "#                 N_tagged += 1\n",
    "#                 print(markers[n-1][0].upper()+' markers tagged: '+ str(N_tagged))\n",
    "#             else:\n",
    "#                 N_tagged += 1\n",
    "\n",
    "#         sliced = bit_df[bit_df.bit.str.startswith(i[0:3])].copy()\n",
    "#         # Get regex filter string\n",
    "#         F = get_regex(i)\n",
    "\n",
    "#         # Tag prefixes that match regex as 'True'\n",
    "#         sliced.loc[sliced.bit.str.fullmatch(F),'prefix'] = True\n",
    "\n",
    "#         bit_df.update(sliced)\n",
    "#     print('Active prefixes updated!')\n",
    "#     return bit_df\n",
    "\n",
    "def get_regex(marker, abcs=string.ascii_lowercase):\n",
    "    # Takes a \"marker\" string and generates regex\n",
    "    # To select all prefixes in that group that\n",
    "    # come alphabetically after that marker\n",
    "\n",
    "    m = marker\n",
    "    # go through marker backwards and omit first 2 letters of marker\n",
    "    # e.g., dragon -> noga\n",
    "    for i,L6 in enumerate(m[::-1][:-2]) :\n",
    "        L5 = m[-i-2]\n",
    "\n",
    "        if i == 0:\n",
    "            if m[-1] == '~': # last character is underscore -> do not include last letter in regex selection\n",
    "                R6 =''\n",
    "                L5 = abcs[abcs.find(L5)+1]\n",
    "            else:\n",
    "                R0 = abcs[abcs.find(L6)]\n",
    "                R6 = '['+ R0 + '-z]' # range of last letter\n",
    "            F = L5 + R6\n",
    "\n",
    "        else:\n",
    "            if L6 == 'z':\n",
    "                R0 = abcs[abcs.find(L6)] # avoid bounds errors when L6 = z\n",
    "            else:\n",
    "                R0 = abcs[abcs.find(L6)+1] # range starts at letter after L6\n",
    "            R = '['+ R0 + '-z]'\n",
    "\n",
    "            F = L5 +'('+R+'|'+F+')' # Add to existing regex\n",
    "\n",
    "\n",
    "    F = m[0]+F+'.*' # add start indicator and .* to select full segment\n",
    "    return F\n",
    "\n",
    "# #--! Regex Generator for Prefix Filtering --------------------------- #\n",
    "# def get_regex(marker):\n",
    "#     # Takes a \"marker\" string and generates regex\n",
    "#     # To select all prefixes in that group that\n",
    "#     # come alphabetically after that marker\n",
    "\n",
    "#     m = marker\n",
    "#     # go through marker backwards and omit first 2 letters of marker\n",
    "#     # e.g., dragon -> noga\n",
    "#     for i,L6 in enumerate(m[::-1][:-2]) :\n",
    "#         L5 = m[-i-2]\n",
    "\n",
    "#         if i == 0:\n",
    "#             if m[-1] == '~': # last character is underscore -> do not include last letter in regex selection\n",
    "#                 R6 =''\n",
    "#                 L5 = abcs[abcs.find(L5)+1]\n",
    "#             else:\n",
    "#                 R0 = abcs[abcs.find(L6)]\n",
    "#                 R6 = '['+ R0 + '-z]' # range of last letter\n",
    "#             F = L5 + R6\n",
    "\n",
    "#         else:\n",
    "#             if L6 == 'z':\n",
    "#                 R0 = abcs[abcs.find(L6)] # avoid bounds errors when L6 = z\n",
    "#             else:\n",
    "#                 R0 = abcs[abcs.find(L6)+1] # range starts at letter after L6\n",
    "#             R = '['+ R0 + '-z]'\n",
    "\n",
    "#             F = L5 +'('+R+'|'+F+')' # Add to existing regex\n",
    "\n",
    "\n",
    "#     F = m[0]+F+'.*' # add start indicator and .* to select full segment\n",
    "#     return F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7540af72",
   "metadata": {},
   "source": [
    "## Build Names From Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "e1896213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_names( name_matrix, N, bits=w_s, stuck=True ):\n",
    "    segments = pd.DataFrame(columns=name_matrix.piece,index=list(range(N)))\n",
    "    ng = name_matrix\n",
    "    for piece in ng.itertuples():\n",
    "        # index = piece[0]\n",
    "        # piece name = piece[1]\n",
    "        L = piece[2]\n",
    "        # regex = piece[3]\n",
    "        \n",
    "        \n",
    "        if piece[1] == piece[3]:\n",
    "            segments.iloc[:,piece[0]] = piece[1]\n",
    "        else:\n",
    "            samply = w_s[w_s.L==L]\n",
    "            \n",
    "            if stuck == True and piece[0] == 0:\n",
    "                if L < 3:\n",
    "                    print('WARNING: Stuck prefixes must have at least 3 letters! Generating non-sticky names.')\n",
    "                    stuck=False\n",
    "                samply = samply[samply.prefix==stuck]\n",
    "                \n",
    "                    \n",
    "            \n",
    "            samply = samply[samply.bit.str.match(piece[3])]\n",
    "            \n",
    "            if len(samply) < N:\n",
    "                rep = True\n",
    "            else:\n",
    "                rep = False\n",
    "            segments.iloc[:,piece[0]] = samply.bit.sample(n = N,replace=rep).reset_index(drop=True)\n",
    "    names = pd.DataFrame(index=segments.index,columns=['Neopet','L'])\n",
    "    names.Neopet = ''\n",
    "    for i in range(len(segments.columns)):\n",
    "            names.Neopet += segments.iloc[:,i]\n",
    "    names.Neopet = names.Neopet.str.capitalize()\n",
    "    names.L = names.Neopet.str.len()\n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d33e286",
   "metadata": {},
   "source": [
    "## Name Generator\n",
    "```python\n",
    "nameGen( name_format, N=300, stuck=True, spread='equal' )\n",
    "```\n",
    "\n",
    "Creates a new Name Generator object.\n",
    "\n",
    "### Parameters\n",
    "\n",
    "####  `name_format` (*str*) :\n",
    "\n",
    "Groups together \"word segments\" that provide a template from which to generate names.\n",
    "\n",
    "\n",
    "#### `N` (*int, default 300*) :\n",
    "\n",
    "Number of names this generator will generate by default. Can be over-ridden.\n",
    "\n",
    "---\n",
    "#### `name_format` Details :\n",
    "\n",
    "| segment | Description |\n",
    "|-:| :- |\n",
    "| **`bit:LL:cvx_s`** | picks random word segments |\n",
    "|  *`:LL`*   | Default: `16`<br>Minimum & max segment lengths |\n",
    "|  *`:cvx_s`*| Default: `.`<br>Constrain word segment characters to certain consonants, vowels, or regex |\n",
    "| **`cvx:L`** | picks random letter/consonant/vowel for each character |\n",
    "| *`:L`* | Default: `1`<br>Repeat the preceeding letters `L` times |\n",
    "|**`string`**| String of letters to be held constant among all generated names |\n",
    "\n",
    "* Use `,` to join segments together. \n",
    "* Note that **`bit::`** and **`cvs:`** *MUST* include all colons.\n",
    "* **``bit::``** and **``cvs:``** will use defaults if no values are specificed after the colons.\n",
    "* For more details, see the page on [creating name format strings](link_eventually).\n",
    "\n",
    "##### Examples:\n",
    "\n",
    "\n",
    "| `name_format`   | Description  | Examples   | Resulting Names | \n",
    "| :-------------: | :----------- | :--------- | :-------------- |\n",
    "|`'bit::,xcv:'`   | word segment, letter, consonant, vowel | `be,are`, `angel,ddo`|Beare, Angelddo | \n",
    "|`'doot,bit:13:'` | 'doot', 1L-3L word segment |`doot,n`, `doot,ezz`| Dootn, Dootezz | \n",
    "|`'v:3,bit:12:.v'`| 3 random vowels, random 1L-2L word segment |`yea,bo`, `ayo,r`|Yeabo, Ayor | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6370bf4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#--! Name Generator class ----------------------------------------- #\n",
    "build_names = nb.build_names\n",
    "class nameGen:\n",
    "    def __init__(self,name_format,N=300,stuck=True,spread='equal'):\n",
    "        # Default Properties\n",
    "        self.nf = name_format.lower()\n",
    "        self.stuck = stuck\n",
    "        self.N = N\n",
    "        self.spread = spread\n",
    "\n",
    "        # Properties to be calculated\n",
    "        self.Lmin = 0\n",
    "        self.Lmax = 0\n",
    "        self.ng = [] # name generator\n",
    "        self.ng_list = []\n",
    "        self.names = []\n",
    "        self.stats = {'time':'','format':'','name_data':''}\n",
    "\n",
    "        # Run other functions\n",
    "        self.get_ng()        # create name generator(s)\n",
    "        self.get_names()     # generate names\n",
    "\n",
    "    def ngs(self):\n",
    "        for i in self.ng_list:\n",
    "            for j in i:\n",
    "                print(j)\n",
    "                print('---')\n",
    "    def update_stats(self):\n",
    "\n",
    "        stats = {}\n",
    "        for i in self.names.L.unique():\n",
    "            ind = (str(i) + ' Letters')\n",
    "            n = len(self.names[self.names.L == i])\n",
    "            stats.update({ ind : n })\n",
    "        stats.update({' ':'---',\n",
    "                      'All Names':len(self.names)\n",
    "                     })\n",
    "\n",
    "\n",
    "        stats = pd.DataFrame.from_dict(stats,orient='index')\n",
    "        stats.columns = [str('NUM')]\n",
    "\n",
    "        self.stats['name_data'] = stats\n",
    "        self.stats['time'] = dt.datetime.now().time().strftime(\"%I:%M:%S %p\")\n",
    "\n",
    "\n",
    "        self.show_stats()\n",
    "\n",
    "    def show_stats(self):\n",
    "        print('\\nNames Updated!')\n",
    "        print('Generator\\n'+'------------------')\n",
    "        print(self.ng)\n",
    "        print('------------------')\n",
    "        print('\\n' + 'Name Stats' +\n",
    "              '\\n' + 'Stuck? ' + str(self.stuck) +\n",
    "              '\\n' + '--------------')\n",
    "        print(self.stats['name_data'])\n",
    "        print('--------------')\n",
    "        print('Last Update @ ' + self.stats['time'])\n",
    "\n",
    "\n",
    "    def get_names(self):\n",
    "\n",
    "        names = pd.DataFrame(columns=['Neopet','L'])\n",
    "\n",
    "        for name_group in self.dd.itertuples():\n",
    "            for i,matrix in enumerate(self.ng_list[name_group[0]]):\n",
    "                temp_names = build_names( matrix, name_group[3], stuck=self.stuck)\n",
    "\n",
    "                names = pd.concat([names,temp_names],ignore_index=True)\n",
    "        names = names.drop_duplicates().sort_values(by=['L','Neopet'])\\\n",
    "                     .reset_index(drop=True)\n",
    "        self.names = names\n",
    "        self.update_stats()\n",
    "        return names\n",
    "\n",
    "    def get_ng(self):\n",
    "        # Create generator\n",
    "        name_format = self.nf\n",
    "        seglist = name_format.split(',')\n",
    "        seg_df = pd.DataFrame({}, columns=['pieces','Lmin','Lmax','regex'])\n",
    "\n",
    "        for seg in seglist:\n",
    "            if ':' in seg:  # segment types denoted by preceeding :\n",
    "                seglist2 = seg.split(':')\n",
    "\n",
    "                if 'bit' in seglist2[0]:\n",
    "\n",
    "                    if len(seglist2[1]) == 2:\n",
    "                    # check bit length range; if not specified, set to default\n",
    "                        Lmin = int(seglist2[1][0])\n",
    "                        Lmax = int(seglist2[1][1])\n",
    "                    else:\n",
    "                        Lmin = 1\n",
    "                        Lmax = 6\n",
    "\n",
    "                    # Interpret regex if included\n",
    "                    if len(seglist2[2])>0:\n",
    "                        regex = r''\n",
    "                        ui = seglist2[2] #user input\n",
    "                        i=0\n",
    "                        ilist = []\n",
    "                        while i < len(ui):\n",
    "                            if ui[i] =='[':\n",
    "\n",
    "                                while ui[i] != ']':\n",
    "                                    regex += ui[i]\n",
    "                                    i+=1\n",
    "                                regex += ']'\n",
    "                            elif ui[i] == '.':\n",
    "                                regex += '.'\n",
    "                                ilist = ilist[:-1]\n",
    "                            else:\n",
    "                                if ui[i] == 'x':\n",
    "                                    regex += '[a-z]'\n",
    "                                elif ui[i] == 'c':\n",
    "                                    regex += '[^aeiouy]'\n",
    "                                elif ui[i] == 'v':\n",
    "                                    regex += '[aeiouy]'\n",
    "\n",
    "                            ilist += [i]\n",
    "                            if len(ilist) > Lmin:\n",
    "                                raise NameError('Cannot define more characters than minimum word segment (\\'bit\\') length; \\nuse \\'.\\' as a placeholder instead.')\n",
    "                            i += 1\n",
    "                        \n",
    "\n",
    "                    else:\n",
    "                        regex = r'[a-z]'*Lmin + r'.'*(Lmax-Lmin)\n",
    "                    seg_df.loc[len(seg_df)] = ['bit*',Lmin,Lmax,regex]\n",
    "\n",
    "                else:\n",
    "#                 'x' in seg or 'v' in seg or 'c' in seg:\n",
    "                    if len(seglist2[1]) > 0:\n",
    "                        L = int(seglist2[1])\n",
    "                        seglist2[0] = seglist2[0]*L\n",
    "                    for l in seglist2[0]:\n",
    "                        if l == 'x':\n",
    "                            seg_df.loc[len(seg_df)] = ['x*',1,1,r'[a-z]']\n",
    "                        elif l =='v':\n",
    "                            seg_df.loc[len(seg_df)] = ['v*',1,1,r'[aeiouy]']\n",
    "                        elif l == 'c':\n",
    "                            seg_df.loc[len(seg_df)] = ['c*',1,1,r'[^aeiouy]']\n",
    "            else:\n",
    "                seg_df.loc[len(seg_df)] = [seg,len(seg),len(seg),seg]\n",
    "\n",
    "\n",
    "        # Update Properties\n",
    "        self.Lmin = seg_df.Lmin.sum()\n",
    "        self.Lmax = seg_df.Lmax.sum()\n",
    "        self.ng = seg_df # name generator\n",
    "\n",
    "        self.get_ng_list()\n",
    "\n",
    "    def get_ng_list(self,bits=w_s):\n",
    "        ng = self.ng\n",
    "        if self.stuck == True:\n",
    "            if ng.pieces[0] in ['x*','v*','c*','bit*'] == True:\n",
    "                while ng.loc[0,'Lmin'] < 3:\n",
    "                    ng.loc[0,'Lmin'] += ng.loc[1,'Lmin']\n",
    "                    ng.loc[0,'Lmax'] += ng.loc[1,'Lmax']\n",
    "                    ng.loc[0,'regex'] += ng.loc[1,'regex']\n",
    "                    ng = ng.drop(1,axis=0).reset_index(drop=True)\n",
    "\n",
    "                ng.loc[0,'pieces'] = 'bit'\n",
    "\n",
    "        ng_list = []\n",
    "        ng_list = [pd.DataFrame(columns=['piece','L','regex'])]\n",
    "\n",
    "        for piece in ng.itertuples():\n",
    "            piece_no = piece[0]\n",
    "            piece_name = piece[1]\n",
    "            Lmin = piece[2]\n",
    "            Lmax = piece[3]\n",
    "            abc_count = piece[4]\n",
    "\n",
    "\n",
    "            if Lmin != Lmax:\n",
    "\n",
    "                ng_list_new = []\n",
    "                for j in range(len(ng_list)):\n",
    "                    for i in range((Lmax-Lmin)+1):\n",
    "                        ng_list_new.append(ng_list[j].copy())\n",
    "\n",
    "                L_list = list(range(Lmin,Lmax+1))\n",
    "                dots = piece[4].count('.')\n",
    "                for i in range(0,len(ng_list_new),len(L_list)):\n",
    "                    for l,L in enumerate(L_list):\n",
    "                        regex = piece[4].replace('.','',dots)\n",
    "                        regex = regex.replace('.','[a-z]')\n",
    "                        ng_list_new[i+l].loc[piece_no] = ['bit*',L,regex]\n",
    "\n",
    "                        dots -=1\n",
    "\n",
    "                ng_list = ng_list_new\n",
    "\n",
    "\n",
    "            else:\n",
    "                for ng_i in ng_list:\n",
    "                    ng_i.loc[piece_no] = [piece_name,Lmin,piece[4]]\n",
    "\n",
    "        dist_data = pd.DataFrame({ 'L':list(range(self.Lmin,self.Lmax+1)) } )\n",
    "        dist_data['N_matrix'] = [0]*len(dist_data)\n",
    "\n",
    "        ng_list2 = [[]]*len(dist_data)\n",
    "        for i in ng_list:\n",
    "            L = i.L.sum()\n",
    "            dist_data.loc[dist_data.L==L,'N_matrix'] += 1\n",
    "            ng_list2[L-self.Lmin] = ng_list2[L-self.Lmin] + [i]\n",
    "\n",
    "\n",
    "        self.ng_list = ng_list2\n",
    "\n",
    "        dist_data['names_per'] = np.ceil(self.N/dist_data.N_matrix/len(dist_data)).astype(int)\n",
    "        self.dd = dist_data\n",
    "\n",
    "#ns = nameGen('bit:35:,bit:23:')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c30e44db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML Updated!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      <link rel=\"stylesheet\" type=\"text/css\" href=\"s...\n",
       "1                                                     \\n\n",
       "2                                 <div class=\"petgroup\">\n",
       "3                                                 \\t<h2>\n",
       "4                                          \\t\\t5 Letters\n",
       "                             ...                        \n",
       "323    \\t<a href=\"http://neopets.com/~Trytwfos\" style...\n",
       "324    \\t<a href=\"http://neopets.com/~Tuoiiuiq\" style...\n",
       "325    \\t<a href=\"http://neopets.com/~Twiurlgy\" style...\n",
       "326                                               </div>\n",
       "327                                                   \\n\n",
       "Length: 328, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288fcc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
